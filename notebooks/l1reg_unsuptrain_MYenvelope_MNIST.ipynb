{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device = cpu\n",
      "torch version = 1.8.0\n",
      "no. of GPUs = 0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-1-f7206c54606b>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     61\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     62\u001B[0m \u001B[0;31m#training dataloader: test the performance for unaligned=False, i.e. for aligned/paired data\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 63\u001B[0;31m train_dataloader = DataLoader(ImageDataset(datapath, transforms_=transform_train_and_test, unaligned=False, mode = 'train'),\\\n\u001B[0m\u001B[1;32m     64\u001B[0m                               batch_size = batch_size, shuffle = True) #the samples must be unaligned and shuffled\n\u001B[1;32m     65\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'number of minibatches during training = %d'\u001B[0m\u001B[0;34m%\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_dataloader\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/Learned-Convex-Prior-Sampling/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers)\u001B[0m\n\u001B[1;32m    264\u001B[0m                     \u001B[0;31m# Cannot statically verify that dataset is Sized\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    265\u001B[0m                     \u001B[0;31m# Somewhat related: see NOTE [ Lack of Default `__len__` in Python Abstract Base Classes ]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 266\u001B[0;31m                     \u001B[0msampler\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mRandomSampler\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgenerator\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mgenerator\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# type: ignore\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    267\u001B[0m                 \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    268\u001B[0m                     \u001B[0msampler\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mSequentialSampler\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/Learned-Convex-Prior-Sampling/lib/python3.8/site-packages/torch/utils/data/sampler.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, data_source, replacement, num_samples, generator)\u001B[0m\n\u001B[1;32m    101\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    102\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnum_samples\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mint\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnum_samples\u001B[0m \u001B[0;34m<=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 103\u001B[0;31m             raise ValueError(\"num_samples should be a positive integer \"\n\u001B[0m\u001B[1;32m    104\u001B[0m                              \"value, but got num_samples={}\".format(self.num_samples))\n\u001B[1;32m    105\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import Dataset\n",
    "from IPython.display import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "from PIL import Image\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision.utils as vutils\n",
    "from skimage.measure import compare_ssim, compare_psnr\n",
    "\n",
    "\n",
    "#writer = SummaryWriter()\n",
    "import warnings\n",
    "warnings.filterwarnings(action='once')\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('device = %s'%device)\n",
    "print('torch version = %s'%(torch.__version__))\n",
    "print('no. of GPUs = %d'%(torch.cuda.device_count()))\n",
    "\n",
    "batch_size, n_in_channels, img_size = 1, 1, 28 #for toy problem\n",
    "val_batch_size = 1\n",
    "#dataloader\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#custom dataset class \n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, root, transforms_= None, unaligned = True, mode = 'train'):\n",
    "        self.transform = transforms.Compose(transforms_)\n",
    "        self.unaligned = unaligned\n",
    "        \n",
    "        self.files = sorted(glob.glob(os.path.join(root, '%s/groundtruth'% mode) + '/*.*'))\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.unaligned:\n",
    "            ground_truth = self.transform(Image.fromarray(np.load(self.files[random.randint(0, len(self.files) - 1)])))\n",
    "        else:\n",
    "            ground_truth = self.transform(Image.fromarray(np.load(self.files[index % len(self.files)])))\n",
    "        \n",
    "        \n",
    "\n",
    "        return {'ground_truth': ground_truth}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "transform_train_and_test = [transforms.ToTensor()]\n",
    "datapath = '../data/MNIST'\n",
    "\n",
    "#training dataloader: test the performance for unaligned=False, i.e. for aligned/paired data\n",
    "train_dataloader = DataLoader(ImageDataset(datapath, transforms_=transform_train_and_test, unaligned=False, mode = 'train'),\\\n",
    "                              batch_size = batch_size, shuffle = True) #the samples must be unaligned and shuffled\n",
    "print('number of minibatches during training = %d'%len(train_dataloader))\n",
    "\n",
    "#modified sigmoid \n",
    "def modified_sigmoid(x, alpha):\n",
    "    x = 1 + torch.exp(-alpha*x)\n",
    "    x = torch.div(torch.ones(x.size()).to(device), x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build a convex discriminator (for 10 x 10 inputs)\n",
    "n_filters = 5 #was 48 previously\n",
    "filt_dim = 5\n",
    "n_layers = 10\n",
    "\n",
    "class icnn_new_model(nn.Module):\n",
    "    def __init__(self, n_in_channels=1, n_filters=n_filters, filt_dim=filt_dim, n_layers=n_layers):\n",
    "        super(icnn_new_model, self).__init__()\n",
    "        \n",
    "        self.n_layers = n_layers\n",
    "        #these layers should have non-negative weights\n",
    "        self.wz = nn.ModuleList([nn.Conv2d(n_filters, n_filters, kernel_size=filt_dim, stride=1, padding=2, bias=False) for i in range(self.n_layers)])\n",
    "        \n",
    "        #these layers can have arbitrary weights\n",
    "        self.wx = nn.ModuleList([nn.Conv2d(n_in_channels, n_filters, kernel_size=filt_dim, stride=1, padding=2, bias=True) for i in range(self.n_layers+1)])\n",
    "        \n",
    "        #one final conv layer with nonnegative weights\n",
    "        self.final_conv2d = nn.Conv2d(n_filters, 1, kernel_size=filt_dim, stride=1, padding=2, bias=False)\n",
    "        \n",
    "        #slope of leaky-relu\n",
    "        self.negative_slope = 0.2 \n",
    "        \n",
    "    def forward(self, x):\n",
    "        z = F.leaky_relu(self.wx[0](x), negative_slope=self.negative_slope)\n",
    "        for layer in range(self.n_layers):\n",
    "            z = F.leaky_relu(self.wz[layer](z) + self.wx[layer+1](x), negative_slope=self.negative_slope)\n",
    "        z = self.final_conv2d(z)\n",
    "        z_avg = F.avg_pool2d(z, z.size()[2:]).view(z.size()[0], -1)\n",
    "        \n",
    "        return z_avg\n",
    "    \n",
    "\n",
    "#realize the model: just one net which outputs a small number for true and large for something noisy \n",
    "mye = icnn_new_model().to(device) \n",
    "\n",
    "\n",
    "#manually initialize weights\n",
    "#the following are initialized with non-negative weights\n",
    "def initialize_weights(net, n_layers = n_layers, min_val = 0.0, max_val = 0.001):\n",
    "    for layer in range(n_layers):\n",
    "        net.wz[layer].weight.data = min_val + (max_val - min_val) * torch.rand(n_filters,n_filters,filt_dim,filt_dim).to(device)\n",
    "    \n",
    "    net.final_conv2d.weight.data = min_val + (max_val - min_val) * torch.rand(1,n_filters,filt_dim,filt_dim).to(device)\n",
    "    return net\n",
    "\n",
    "mye = initialize_weights(mye)\n",
    "\n",
    "#for debugging\n",
    "dummy_input = torch.rand(batch_size, n_in_channels, img_size, img_size).to(device)\n",
    "mye_output = mye(dummy_input)\n",
    "print(mye_output.size())\n",
    "\n",
    "total_params = sum(p.numel() for p in mye.parameters())\n",
    "print('total number of parameters in MYE = %d'%total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### FOR DEBUGGING ###### \n",
    "\n",
    "#check the contributions of each term in the ACR\n",
    "noise_sd_for_training_stability = 0.0\n",
    "for idx, batch in enumerate(train_dataloader):\n",
    "    ############################################\n",
    "    images = batch[\"ground_truth\"].to(device) #true images\n",
    "    batch_size = images.size()[0]\n",
    "\n",
    "    #true images + slight noise for stability\n",
    "    real_x = images + noise_sd_for_training_stability*torch.randn(batch_size,n_in_channels,img_size,img_size).to(device) \n",
    "    \n",
    "    #for true image\n",
    "    mye_output = mye(real_x)\n",
    "    print('--- response to true image ---')\n",
    "    print('contribution of the leaky-relu network = %.6f'%torch.sum(mye_output))\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#non-negativity penalty\n",
    "def clamp_weights(net, n_layers = n_layers): #set negative weights to 0\n",
    "    for layer in range(n_layers):\n",
    "        net.wz[layer].weight.data.clamp_(0)\n",
    "    \n",
    "    net.final_conv2d.weight.data.clamp_(0)\n",
    "    return net\n",
    "\n",
    "import torch.autograd as autograd\n",
    "def compute_gradient(net, samples): \n",
    "    interpolates = (samples).requires_grad_(True)\n",
    "    validity = net(interpolates)\n",
    "    fake = Variable(torch.FloatTensor(np.ones(validity.shape)), requires_grad=False)\n",
    "    # Get gradient w.r.t. interpolates\n",
    "    gradients = autograd.grad(outputs=validity, inputs=interpolates,\n",
    "                              grad_outputs=fake, create_graph=True, retain_graph=True,\n",
    "                              only_inputs=True)[0]\n",
    "    \n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    \n",
    "    return gradients\n",
    "\n",
    "def compute_hessian_penalty():\n",
    "    k=9\n",
    "\n",
    "def compute_l1_mye_penalty(samples, gradient, alpha, lamb): # for a general regularizer, we can use a simular function\n",
    "    # Compute l2 gradient norm loss\n",
    "    gradient_penalty = 1./2 * (gradient.norm(2, dim=1) ** 2).mean() \n",
    "    # Compute prior loss, i.e., l1 loss\n",
    "    samples = samples.view(samples.size(0),-1)\n",
    "    prior_penalty = (samples - lamb * gradient).norm(1, dim=1).mean()\n",
    "    \n",
    "    loss = lamb**2 * gradient_penalty + lamb * alpha * prior_penalty\n",
    "\n",
    "    return loss, lamb**2 * gradient_penalty, lamb * alpha * prior_penalty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########\n",
    "import itertools\n",
    "betas = (0.5, 0.99) \n",
    "\n",
    "#trained without FoE\n",
    "#optimizer_acr = torch.optim.Adam(itertools.chain(acr.parameters(),l2_net.parameters()), lr=2*1e-5, betas=betas, weight_decay=0.0)\n",
    "\n",
    "# #when trained with FoE included\n",
    "optimizer_mye = torch.optim.Adam(mye.parameters(), lr=2*1e-3, betas=betas, weight_decay=0.0)\n",
    "\n",
    "# proximal map related variables\n",
    "lamb = 1.\n",
    "alpha = 1.\n",
    "\n",
    "noise_sd_for_training_stability = 0.1\n",
    "n_epochs = 10\n",
    "num_minibatches = 20 #for display\n",
    "\n",
    "avg_loss_mye_paired = []\n",
    "\n",
    "for epoch in np.arange(n_epochs):\n",
    "    \n",
    "    #restart scheduler and reset losses\n",
    "    scheduler_mye = torch.optim.lr_scheduler.StepLR(optimizer_mye, step_size=20, gamma=0.9)\n",
    "    total_loss = 0.0\n",
    "    total_gp_loss = 0.0\n",
    "    total_pp_loss = 0.0\n",
    "    \n",
    "    for idx, batch in enumerate(train_dataloader):\n",
    "        \n",
    "        ############################################\n",
    "        images = batch[\"ground_truth\"].to(device) #true images\n",
    "        batch_size = images.size()[0]\n",
    "        \n",
    "        #true images + slight noise for stability\n",
    "        real_x = images + noise_sd_for_training_stability*torch.randn(batch_size,n_in_channels,img_size,img_size).to(device) \n",
    "        \n",
    "        gradient = compute_gradient(mye,real_x)\n",
    "        \n",
    "        loss, gp_loss, pp_loss = compute_l1_mye_penalty(real_x, gradient, alpha, lamb)\n",
    "        \n",
    "        #parameter update\n",
    "        optimizer_mye.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_mye.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_gp_loss += gp_loss.item()\n",
    "        total_pp_loss += pp_loss.item()\n",
    "        \n",
    "        #clamp negative weights to 0\n",
    "        mye = clamp_weights(mye) \n",
    "        #take scheduler steps\n",
    "        scheduler_mye.step()\n",
    "        \n",
    "        if(idx % num_minibatches == num_minibatches-1):\n",
    "            ####### compute avg. loss over minibatches #######\n",
    "            avg_loss = total_loss/num_minibatches\n",
    "            avg_gp_loss = total_gp_loss/num_minibatches\n",
    "            avg_pp_loss = total_pp_loss/num_minibatches\n",
    "            \n",
    "            avg_loss_mye_paired.append(avg_loss)\n",
    "            \n",
    "            #reset the losses\n",
    "            total_loss = 0.0\n",
    "            total_gp_loss = 0.0\n",
    "            total_pp_loss = 0.0\n",
    "            \n",
    "            print('==================')\n",
    "            print('----single convex MYE----')\n",
    "            print(\"epoch: [{}/{}], mini-batch: [{}/{}], avg_loss: {:.8f}, avg_gp_loss: {:.8f}, avg_pp_loss: {:.8f}\".\\\n",
    "                  format(epoch+1, n_epochs, idx+1, len(train_dataloader), avg_loss, avg_gp_loss, avg_pp_loss))\n",
    "            \n",
    "            print('--- response to true image ---')\n",
    "            mye_output_true = mye(real_x)\n",
    "            print('contribution of the leaky-relu network = %.6f'%torch.sum(mye_output_true))\n",
    "\n",
    "#             mye_output_fbp = mye(fake_x)\n",
    "#             print('--- response to FBP ---')\n",
    "#             print('contribution of the leaky-relu network = %.6f'%torch.sum(acr_output_fbp))\n",
    "#             print('contribution of the FoE network = %.6f'%torch.sum(foe_output_fbp))\n",
    "#             print('contribution of the l2-term = %.6f'%torch.sum(l2_term_fbp))\n",
    "    \n",
    "            #save the models \n",
    "            pretrained_network_path = '../models/l1reg_pretrained_nets/'\n",
    "            os.makedirs(pretrained_network_path, exist_ok=True)\n",
    "#             torch.save(acr.state_dict(),  pretrained_network_path + \"acr_new_model_foe_included_\" + 'epoch_%02d'%epoch + \".pt\") \n",
    "#             torch.save(foe.state_dict(),  pretrained_network_path + \"foe_net_foe_included_\" + 'epoch_%02d'%epoch + \".pt\") \n",
    "#             torch.save(l2_net.state_dict(),  pretrained_network_path + \"l2_term_foe_included_\" + 'epoch_%02d'%epoch + \".pt\") \n",
    "\n",
    "            torch.save(mye.state_dict(),  pretrained_network_path + \"mye_new_model_foe_included_paired.pt\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the models \n",
    "pretrained_network_path = '../models/l1reg_pretrained_nets/'\n",
    "os.makedirs(pretrained_network_path, exist_ok=True)\n",
    "# torch.save(acr.state_dict(),  pretrained_network_path + \"acr_new_model_foe_included_\" + 'epoch_%02d'%epoch + \".pt\") \n",
    "# torch.save(foe.state_dict(),  pretrained_network_path + \"foe_net_foe_included_\" + 'epoch_%02d'%epoch + \".pt\") \n",
    "# torch.save(l2_net.state_dict(),  pretrained_network_path + \"l2_term_foe_included_\" + 'epoch_%02d'%epoch + \".pt\") \n",
    "\n",
    "# torch.save(acr.state_dict(),  pretrained_network_path + \"acr_new_model_foe_included_paired.pt\")\n",
    "# torch.save(foe.state_dict(),  pretrained_network_path + \"foe_net_foe_included_paired.pt\")\n",
    "# torch.save(l2_net.state_dict(),  pretrained_network_path + \"l2_term_foe_included_paired.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "pretrained_network_path = '../models/l1reg_pretrained_nets/'\n",
    "\n",
    "avg_loss_mye_paired_arr = np.array(avg_loss_mye_paired, dtype=np.float32)\n",
    "# avg_loss_mye_unpaired_arr = np.load(pretrained_network_path + \"avg_loss_mye_unpaired_arr.npy\")\n",
    "np.save(pretrained_network_path + \"avg_loss_mye_paired_arr.npy\", avg_loss_mye_paired_arr)\n",
    "train_steps = np.arange(1, 1+avg_loss_mye_paired_arr.size)\n",
    "\n",
    "# plt.plot(train_steps, avg_loss_mye_paired_arr, 'r', train_steps, avg_loss_acr_unpaired_arr, 'b', linewidth=2.0)\n",
    "# plt.legend(['paired', 'unpaired'], fontsize=24.0)\n",
    "\n",
    "\n",
    "plt.plot(train_steps, avg_loss_mye_paired_arr, 'r', linewidth=2.0)\n",
    "\n",
    "# plt.plot(train_steps, avg_loss_mye_unpaired_arr, 'b', linewidth=2.0)\n",
    "\n",
    "plt.gcf().set_size_inches(11.0,8.0)\n",
    "plt.xlabel('training steps', fontsize=28.0)\n",
    "plt.ylabel('training loss', fontsize=28.0)\n",
    "plt.tick_params(axis='both', which='major', labelsize=24.0)\n",
    "plt.grid()\n",
    "\n",
    "plt.savefig(pretrained_network_path + 'unpaired_train.png', bbox_inches='tight', transparent = False, pad_inches=0.1)\n",
    "#plt.savefig(pretrained_network_path + 'paired_vs_unpaired_train_combined.png', bbox_inches='tight', transparent = False, pad_inches=0.1)\n",
    "#plt.savefig(pretrained_network_path + 'paired_train.png', bbox_inches='tight', transparent = False, pad_inches=0.1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check convexity of the net\n",
    "n_trials = 50\n",
    "convexity = 0\n",
    "for trial in np.arange(n_trials):\n",
    "    x1 = torch.rand(dummy_input.size()).to(device)\n",
    "    x2 = torch.rand(dummy_input.size()).to(device)\n",
    "    alpha = torch.rand(1).to(device)\n",
    "\n",
    "    cvx_combo_of_input = mye(alpha * x1 + (1-alpha)*x2)\n",
    "    cvx_combo_of_output = alpha * mye(x1) + (1-alpha)*mye(x2)\n",
    "\n",
    "    convexity += (cvx_combo_of_input.mean() <= cvx_combo_of_output.mean())\n",
    "if(convexity == n_trials):\n",
    "    print('the net is %s'%'convex') \n",
    "else:\n",
    "    print('the net is %s'%'non-convex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare output to exact solution\n",
    "import matplotlib.pyplot as plt\n",
    "steps = 100\n",
    "\n",
    "sample = next(iter(train_dataloader))[\"ground_truth\"]\n",
    "sample_ = sample.detach().numpy()[0][0]\n",
    "plt.imshow(sample_, cmap=plt.get_cmap('gray'))\n",
    "plt.show()\n",
    "\n",
    "x_ij = torch.linspace(start=0., end=1.,steps=steps)\n",
    "x = torch.zeros((steps,) + sample[0].shape)\n",
    "for k in range(steps):\n",
    "    x[k,0] = sample\n",
    "    x[k,0,2,3] = x_ij[k]\n",
    "\n",
    "\n",
    "# x = sample[0]\n",
    "# print(x.shape)\n",
    "# x.expand(steps, 28, 28) # specifies new size\n",
    "# print(x.shape)\n",
    "# x.repeat(steps,1,1,1) # specifies number of copies\n",
    "\n",
    "# x[:,0,2,3] = x_ij\n",
    "\n",
    "new_sample_ = x.detach().numpy()[50][0]\n",
    "plt.imshow(new_sample_, cmap=plt.get_cmap('gray'))\n",
    "plt.show()\n",
    "g_lambda = mye(x)\n",
    "    \n",
    "def mye_l1(lambd,x):\n",
    "    z = np.zeros((x.shape[0], x.shape[2], x.shape[3]))\n",
    "    for k in range(x.shape[0]):\n",
    "        for i in range(x.shape[2]):\n",
    "            for j in range(x.shape[3]):\n",
    "#                 if i==2 and j==3:\n",
    "#                     print(x[k,0,i,j])\n",
    "                if x[k,0,i,j].abs() < lambd:\n",
    "                    z[k,i,j] = 1/(2*lambd) * x[k,0,i,j]**2\n",
    "                else:\n",
    "                    z[k,i,j] = np.abs(x[k,0,i,j]) - lambd/2\n",
    "\n",
    "    mye = np.sum(z,axis=(1,2))\n",
    "\n",
    "    return mye\n",
    "        \n",
    "    \n",
    "gt = mye_l1(alpha*lamb,x)\n",
    "print(gt.shape)\n",
    "\n",
    "plt.plot(x_ij.detach().numpy(),g_lambda.detach().numpy())\n",
    "plt.plot(x_ij.detach().numpy(),gt)\n",
    "# Plot ground truth\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}